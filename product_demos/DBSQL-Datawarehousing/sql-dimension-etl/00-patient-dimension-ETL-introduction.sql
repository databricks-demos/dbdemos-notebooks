-- Databricks notebook source
-- MAGIC %md-sandbox
-- MAGIC # Demo: Create & Populate Type 2 Patient Dimension
-- MAGIC
-- MAGIC The demo will illustrate the data architecture and data workflow that creates and populates a dimension in a Star Schema using **Databricks SQL**.
-- MAGIC This will utilize a Patient dimension in the Healthcare domain.
-- MAGIC The demo will illustrate all facets of an end-to-end ETL to transform, validate, and load an SCD2 dimension.
-- MAGIC <br><br>
-- MAGIC Note: The ETL assumes that the source data is extracted to cloud storage as incremental CSV files.
-- MAGIC

-- COMMAND ----------

-- MAGIC %md-sandbox
-- MAGIC # What We Will Build
-- MAGIC
-- MAGIC #### This end-to-end demo builds a Workflows Job that will perform the following tasks:
-- MAGIC
-- MAGIC ####<span style="color:darkblue">1. Create Tables
-- MAGIC <br>
-- MAGIC   a) Global Configuration
-- MAGIC -  **ETL Log table**: This table captures the runtime metadata for a table that includes the table name, load start time and load end time.
-- MAGIC  
-- MAGIC   _See [Create Log Table notebook]($./02-Create/02.2-create-ETL-log-table) to review._
-- MAGIC
-- MAGIC   b) Standardization<br>
-- MAGIC -  **Codes table**: Master table initialized with standardized codes used for coded attributes in the schema.<br>
-- MAGIC
-- MAGIC   _See [Create Code Table notebook]($./02-Create/02.1-create-code-table) to review._
-- MAGIC
-- MAGIC   c) Patient tables<br>
-- MAGIC - **Patient Staging table**
-- MAGIC - **Patient Integration table**
-- MAGIC - **Patient Dimension table**
-- MAGIC <br>
-- MAGIC
-- MAGIC _See [Create Patient Tables notebook]($./02-Create/02.3-create-patient-tables) to review._
-- MAGIC
-- MAGIC #### <span style="color:darkblue">2. Stage Initial Data<br>
-- MAGIC   This task will copy / upload an initial CSV file with patient data onto a staging Volume.
-- MAGIC
-- MAGIC ####<span style="color:darkblue">3. Patient load<br>
-- MAGIC This will initiate the ETL which will read new files from the staging Volume and populate the staging, integration, and patient dimension tables.
-- MAGIC
-- MAGIC ####<span style="color:darkblue">4. Stage Incremental Data<br>
-- MAGIC   This task will copy / upload two incremental CSV files with patient data onto the staging Volume.
-- MAGIC
-- MAGIC ####<span style="color:darkblue">5. Patient load<br>
-- MAGIC This will initiate the ETL which will read new files from the staging Volume and populate the staging, integration, and patient dimension tables.
-- MAGIC
-- MAGIC _See [Patient Dimension ETL notebook]($./03-Populate/03.1-patient-dimension-ETL) to review._
-- MAGIC
-- MAGIC <br>
-- MAGIC You can also browse the results of each ETL run. This will show the data that is present in the log table and patient tables, as it appears at the end of the initial load and each incremental load. Click on each of <b>demo_BrowseResultInit</b> and <b>demo_BrowseResultIncr</b> tasks after navigating to the job run page.

-- COMMAND ----------

-- MAGIC %md-sandbox
-- MAGIC # Table Definitions
-- MAGIC
-- MAGIC #### <span style="color:darkblue">Patient tables created in the Data Warehouse
-- MAGIC
-- MAGIC ![](https://github.com/databricks-demos/dbdemos-resources/blob/main/images/dbsql/sql-etl-hls-patient/patient_tables_dw.png?raw=true)
-- MAGIC
-- MAGIC You can view the tables within the catalog.schema that is specified in notebook 00-Setup/Initialize.

-- COMMAND ----------

-- MAGIC %md-sandbox
-- MAGIC # Data Flow
-- MAGIC
-- MAGIC #### <span style="color:darkblue">Flow of data from the Staging Area for the source data files to the Patient Dimension table
-- MAGIC <br>
-- MAGIC
-- MAGIC <div style="border: 1px solid grey; padding: 1px; display: inline-block;">
-- MAGIC
-- MAGIC ![](https://github.com/databricks-demos/dbdemos-resources/blob/main/images/dbsql/sql-etl-hls-patient/data_flow_no_excpt.png?raw=true)
-- MAGIC
-- MAGIC
-- MAGIC </div>
-- MAGIC

-- COMMAND ----------

-- MAGIC %md-sandbox
-- MAGIC # Sample Source Data
-- MAGIC
-- MAGIC #### <span style="color:darkblue">Patient data as contained in the source files
-- MAGIC
-- MAGIC ![](https://github.com/databricks-demos/dbdemos-resources/blob/main/images/dbsql/sql-etl-hls-patient/patient_data.png?raw=true)
