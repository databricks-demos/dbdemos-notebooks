-- Databricks notebook source
-- MAGIC %md
-- MAGIC ### Example Exploratory Notebook
-- MAGIC
-- MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
-- MAGIC
-- MAGIC **Note**: This notebook is not executed as part of the pipeline.

-- COMMAND ----------

-- MAGIC %python
-- MAGIC catalog = "main__build"
-- MAGIC schema = dbName = db = "dbdemos_fsi_credit_decisioning"
-- MAGIC volume_name = "credit_raw_data"

-- COMMAND ----------

-- DBTITLE 1,Explore credit bureau data (JSON)
-- MAGIC %python
-- MAGIC sdf = spark.read.json(f"/Volumes/{catalog}/{db}/{volume_name}/credit_bureau")
-- MAGIC display(sdf)

-- COMMAND ----------

-- DBTITLE 1,Explore customer data (CSV)
-- MAGIC %python
-- MAGIC sdf = spark.read.format("csv").option("header", True).load(f"/Volumes/{catalog}/{db}/{volume_name}/internalbanking/customer")
-- MAGIC display(sdf)

-- COMMAND ----------

-- DBTITLE 1,Explore relationship data (CSV)
-- MAGIC %python
-- MAGIC sdf = spark.read.format("csv").option("header", True).load(f"/Volumes/{catalog}/{db}/{volume_name}/internalbanking/relationship")
-- MAGIC display(sdf)

-- COMMAND ----------

-- DBTITLE 1,Explore account data (CSV)
-- MAGIC %python
-- MAGIC sdf = spark.read.format("csv").option("header", True).load(f"/Volumes/{catalog}/{db}/{volume_name}/internalbanking/account")
-- MAGIC display(sdf)

-- COMMAND ----------

-- DBTITLE 1,Explore fund transfer data (JSON)
-- MAGIC %python
-- MAGIC sdf = spark.read.json(f"/Volumes/{catalog}/{db}/{volume_name}/fund_trans")
-- MAGIC display(sdf)

-- COMMAND ----------

-- DBTITLE 1,Explore telco partner data (JSON)
-- MAGIC %python
-- MAGIC sdf = spark.read.json(f"/Volumes/{catalog}/{db}/{volume_name}/telco")
-- MAGIC display(sdf)
