{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3534271-e1d8-4d17-837b-bdd44a7a4bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023cd9f1-a1ec-4a88-9d55-a185bcef898f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105ca9cc-741a-4375-aada-1123ef202e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'use catalog {catalog}')\n",
    "spark.sql(f'use schema {dbName}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13a44f6d-77ce-44d6-919f-ec5c3b91076b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate a synthetic evaluation dataset for customer data and billing questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d9eca9f-2643-4823-9c90-2429a601a293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, pandas_udf, concat_ws, lit, col, from_json, struct, expr\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load 20 customers\n",
    "df = spark.table(\"customers\").limit(20).withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# Step 2: Generate question using 20 templates\n",
    "@pandas_udf(StringType())\n",
    "def generate_question(email: pd.Series, row_id: pd.Series) -> pd.Series:\n",
    "    templates = [\n",
    "        \"What is the phone number of {email}?\",\n",
    "        \"List all orders placed by {email}.\",\n",
    "        \"What is the current subscription status for {email}?\",\n",
    "        \"Show billing details for {email}.\",\n",
    "        \"Does {email} have any unpaid invoices?\",\n",
    "        \"Which products did {email} purchase?\",\n",
    "        \"What is the loyalty tier of {email}?\",\n",
    "        \"When did {email} register as a customer?\",\n",
    "        \"Summarize all subscriptions held by {email}.\",\n",
    "        \"What city does {email} live in?\",\n",
    "        \"What is the current account status of {email}?\",\n",
    "        \"How many years has {email} been a customer?\",\n",
    "        \"What is the churn risk score for {email}?\",\n",
    "        \"What is the customer value score for {email}?\",\n",
    "        \"Is autopay enabled for {email}'s account?\",\n",
    "        \"How many late payments has {email} had?\",\n",
    "        \"What is the zip code of {email}?\",\n",
    "        \"What type of customer is {email} (e.g., Individual, Business)?\",\n",
    "        \"What is the full address of {email}?\"\n",
    "    ]\n",
    "    return pd.Series([\n",
    "        templates[int(i) % len(templates)].format(email=e)\n",
    "        for i, e in zip(row_id, email)\n",
    "    ])\n",
    "\n",
    "df = df.withColumn(\"question\", generate_question(\"email\", \"row_id\"))\n",
    "\n",
    "# Step 3: Convert to Pandas then back to Spark to finalize UDF materialization\n",
    "df_pd = df.toPandas()\n",
    "df_clean = spark.createDataFrame(df_pd)\n",
    "\n",
    "# Step 4: Build prompt for AI_QUERY\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"prompt\",\n",
    "    concat_ws(\n",
    "        \" \",\n",
    "        lit(\"You are evaluating an AI system.\"),\n",
    "        lit(\"Based on the following customer record:\"),\n",
    "        concat_ws(\", \",\n",
    "            df_clean.first_name, df_clean.last_name, df_clean.email, df_clean.phone,\n",
    "            df_clean.address, df_clean.city, df_clean.state, df_clean.zip_code,\n",
    "            df_clean.customer_segment, df_clean.registration_date.cast(\"string\"),\n",
    "            df_clean.customer_status, df_clean.loyalty_tier,\n",
    "            df_clean.tenure_years.cast(\"string\"), df_clean.churn_risk_score.cast(\"string\"),\n",
    "            df_clean.customer_value_score.cast(\"string\")\n",
    "        ),\n",
    "        lit(\"Generate a JSON array of factual statements (expected_facts) that should be included in the correct answer to the following question. Each item must be a complete, natural language sentence. Return only a valid JSON array of strings, nothing else.\"),\n",
    "        lit(\"Question:\"), df_clean.question\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 5: Register and call AI_QUERY\n",
    "df_clean.createOrReplaceTempView(\"customer_test_questions\")\n",
    "\n",
    "final_df_raw = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  question,\n",
    "  AI_QUERY(\"databricks-claude-3-7-sonnet\", prompt) AS expected_facts_json\n",
    "FROM customer_test_questions\n",
    "\"\"\")\n",
    "\n",
    "# Step 6: Parse JSON string into Array<String>\n",
    "final_df = final_df_raw.withColumn(\n",
    "    \"expected_facts\",\n",
    "    from_json(col(\"expected_facts_json\"), ArrayType(StringType()))\n",
    ")\n",
    "\n",
    "# Step 7: Build structured evaluation format\n",
    "eval_df = final_df.withColumn(\"inputs\", struct(\"question\")) \\\n",
    "                  .withColumn(\"predictions\", lit(\"\")) \\\n",
    "                  .withColumn(\"expectations\", struct(\"expected_facts\")) \\\n",
    "                  .select(\"inputs\", \"predictions\", \"expectations\")\n",
    "\n",
    "# Step 8: Save\n",
    "eval_df.write.format('json').mode(\"overwrite\").save(f\"/Volumes/{catalog}/{dbName}/{volume_name}/eval_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec00eb5e-bc71-4794-acfb-c2e9696a0eaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(eval_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_c75093c8-0895-475e-8c1b-6acacfe3368b",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04-eval-dataset-generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
