{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a555ed11-89b5-4e6f-ac55-9c19e0a6cbe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks SQL\n",
    "<br>\n",
    "\n",
    "<div style=\"float: right; width: 100%;\">\n",
    "  <img \n",
    "    src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/dbsql/sql-etl-hls-patient/Databricks%20SQL%20Intro.png?raw=true\" \n",
    "    width=\"100%\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6008ccf2-cb0b-43fe-b747-5065cce504c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# End-to-End Data Warehousing Solution\n",
    "<br>\n",
    "\n",
    "<div style=\"float: right; width: 100%;\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/dbsql/sql-etl-hls-patient/Databricks%20SQL%20Marketecture.png?raw=true\" style=\"float: right\" width=\"100%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaccd06a-8377-47a3-b16c-3a7588bd0421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# SQL Centric Engine Capabilities\n",
    "\n",
    "Let's first start with some examples of Databricks SQL capabilities before moving onto the full-fledged example of Creating and Populating a dimension in a Star Schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd19d42c-d7c3-48a3-9a0a-d18dc1f2af3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Declare Variable\n",
    "\n",
    "Variables are typed objects which store values that are private to a session. In Databricks variables are temporary and declared within a session using the DECLARE VARIABLE statement.\n",
    "\n",
    "Public Documentation: [AWS](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-syntax-ddl-declare-variable) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-syntax-ddl-declare-variable) | [GCP](https://docs.databricks.com/gcp/en/sql/language-manual/sql-ref-syntax-ddl-declare-variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66080547-f9e9-4963-90a9-87e24182fce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Storage location for demo sample files\n",
    "DECLARE OR REPLACE VARIABLE cloud_loc STRING;\n",
    "SET VARIABLE cloud_loc = \"s3://dbdemos-dataset/dbsql/sql-etl-hls-patient\";\n",
    "\n",
    "-- List of sample patient data file names\n",
    "DECLARE OR REPLACE VARIABLE file_names ARRAY<STRING>;\n",
    "SET VARIABLE file_names = array('patients50_init.csv', 'patients_incr1.csv', 'patients_incr2.csv', 'NOTICE.txt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e58b653-bef4-441c-9367-5f1cf422e58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. SQL Scripting\n",
    "\n",
    "- Write complex logic with Pure SQL\n",
    "- Combine SQL Statements with Control Flow \n",
    "- SQL/PSM standard\n",
    "- Refer to Public Documentation: [AWS](https://docs.databricks.com/aws/en/sql/language-manual/sql-ref-scripting) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-scripting) | [GCP](https://docs.databricks.com/gcp/pt/sql/language-manual/sql-ref-scripting)\n",
    "\n",
    "![](https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/refs/heads/main/images/dbsql/sql-etl-hls-patient/SQL%20Scripting.png?raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4383ed7-1b7b-4564-b07b-2ca18e9d05c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "The SQL Script below does the following:<br>\n",
    "\n",
    "Loop through the 3 patient sample data files to-\n",
    "1. Identify the headers\n",
    "2. Create persistent views in the current schema\n",
    "\n",
    "<u>NOTE</u>:\n",
    "The SQL script below will create or **replace** any existing views with the following names, in the current schema:\n",
    "- dbdemos_patients50_init\n",
    "- dbdemos_patients_incr1\n",
    "- dbdemos_patients_incr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "368abc59-295a-46ff-a327-49b356f0fc47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Explore format of sample patient data files\n",
    "BEGIN\n",
    "  DECLARE first_row STRING;\n",
    "  DECLARE result_arr ARRAY<STRING> DEFAULT array();\n",
    "  DECLARE sqlstr STRING;\n",
    "  DECLARE view_name STRING;\n",
    "\n",
    "  -- Drop the 3 views if existing\n",
    "  -- These are created in this script\n",
    "  DROP VIEW IF EXISTS dbdemos_patients50_init;\n",
    "  DROP VIEW IF EXISTS dbdemos_patients_incr1;\n",
    "  DROP VIEW IF EXISTS dbdemos_patients_incr2;\n",
    "\n",
    "  lbl_for_loop:\n",
    "  FOR filelist AS (SELECT explode(file_names) AS file_name)\n",
    "  DO\n",
    "    -- For each file (name), do\n",
    "\n",
    "    -- Read first line from file into variable\n",
    "    SET first_row = (SELECT * FROM read_files(cloud_loc || '/' ||  filelist.file_name, format=>'TEXT') LIMIT 1);\n",
    "\n",
    "    IF (first_row IS NOT NULL)\n",
    "    THEN\n",
    "\n",
    "      IF startswith(first_row, 'Id,')\n",
    "      THEN\n",
    "        -- First line of file starts with Id column\n",
    "        -- Record this in result_arr\n",
    "        SET result_arr = array_append(result_arr, filelist.file_name || ' header: \\n' || first_row);\n",
    "\n",
    "        -- Create view for ease of data exploration\n",
    "        SET view_name = 'dbdemos_' || rtrim('.csv', filelist.file_name);\n",
    "\n",
    "        -- Note: Any temp view is limited to current scope\n",
    "        -- Below EXECUTE will create persistent view in the CURRENT SCHEMA\n",
    "        SET sqlstr = 'CREATE VIEW ' || view_name ||\n",
    "          ' AS SELECT * FROM read_files(\\'' || cloud_loc || '/' ||  filelist.file_name || '\\')';\n",
    "        EXECUTE IMMEDIATE sqlstr;\n",
    "      ELSE\n",
    "        SET result_arr = array_append(result_arr, filelist.file_name || ': ' || 'Header not present');\n",
    "      END IF;\n",
    "      \n",
    "    ELSE\n",
    "      -- file empty\n",
    "      SET result_arr = array_append(result_arr, filelist.file_name || ': ' || 'File empty');\n",
    "    END IF;\n",
    "\n",
    "  END FOR lbl_for_loop;\n",
    "\n",
    "  -- Show results for csv file header\n",
    "  SELECT explode(result_arr) AS result;\n",
    " END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5ecc86-f431-4e3e-8487-5ec5710dddb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Browse data from the 3 views created in the script\n",
    "SELECT * FROM dbdemos_patients50_init;\n",
    "SELECT * FROM dbdemos_patients_incr1;\n",
    "SELECT * FROM dbdemos_patients_incr2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6309ed1b-aaa6-4aed-8d8a-65dd7f9c193e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Drop the 3 views created in the script\n",
    "DROP VIEW IF EXISTS dbdemos_patients50_init;\n",
    "DROP VIEW IF EXISTS dbdemos_patients_incr1;\n",
    "DROP VIEW IF EXISTS dbdemos_patients_incr2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccf8b02c-a593-4251-b533-e660d2a9759b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Ok you're now ready, let's get started with a full example \n",
    "\n",
    "This example will create and populate a SCD Type 2 dimension using Databricks SQL.\n",
    "\n",
    "[Patient Dimension ETL Introduction]($./01-patient-dimension-ETL-introduction)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00-get-started-with-SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
